{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tennis match prediction and playing strategy -- Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "1. Try different algorithms and build the prediction model, using accuracy as our evaluation metrics\n",
    "    * Naive Bayes\n",
    "    * K-Nearest Neighbors\n",
    "    * Logistic Regression\n",
    "    * Decision Tree\n",
    "    * Random Forest\n",
    "    * Support Vector Machine\n",
    "    * Gradient Boosting\n",
    "    \n",
    "2. Compare the performance of different feature selection methods\n",
    "    * statistical-based\n",
    "    * model-based\n",
    "    * PCA\n",
    "\n",
    "3. Deep learning using RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# import model package\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scipy.stats as stats\n",
    "\n",
    "# import customized package\n",
    "from MLuseful import get_best_model_accuracy\n",
    "from MLuseful import roc_curve_plot\n",
    "from MLuseful import print_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "We will load the training and testing set from the feature engineering step and we will be ready to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tennis_all_feature_clean_X_train = pd.read_csv('../Processed_Data/tennis_all_feature_clean_X_train.csv')\n",
    "tennis_all_feature_clean_X_test = pd.read_csv('../Processed_Data/tennis_all_feature_clean_X_test.csv')\n",
    "tennis_all_feature_clean_y_train = pd.read_csv('../Processed_Data/tennis_all_feature_clean_y_train.csv', header=None)\n",
    "tennis_all_feature_clean_y_test = pd.read_csv('../Processed_Data/tennis_all_feature_clean_y_test.csv', header=None)\n",
    "tennis_all_feature_clean_drop_oppo_X_train = pd.read_csv('../Processed_Data/tennis_all_feature_clean_drop_oppo_X_train.csv')\n",
    "tennis_all_feature_clean_drop_oppo_X_test = pd.read_csv('../Processed_Data/tennis_all_feature_clean_drop_oppo_X_test.csv')\n",
    "tennis_all_feature_clean_drop_oppo_y_train = pd.read_csv('../Processed_Data/tennis_all_feature_clean_drop_oppo_y_train.csv', header=None)\n",
    "tennis_all_feature_clean_drop_oppo_y_test = pd.read_csv('../Processed_Data/tennis_all_feature_clean_drop_oppo_y_test.csv', header=None)\n",
    "\n",
    "tennis_all_feature_clean_X_train_p_value = pd.read_csv('../Processed_Data/tennis_all_feature_clean_X_train_p_value.csv')\n",
    "tennis_all_feature_clean_X_test_p_value = pd.read_csv('../Processed_Data/tennis_all_feature_clean_X_test_p_value.csv')\n",
    "tennis_all_feature_clean_drop_oppo_X_train_p_value = pd.read_csv('../Processed_Data/tennis_all_feature_clean_drop_oppo_X_train_p_value.csv')\n",
    "tennis_all_feature_clean_drop_oppo_X_test_p_value = pd.read_csv('../Processed_Data/tennis_all_feature_clean_drop_oppo_X_test_p_value.csv')\n",
    "\n",
    "tennis_all_feature_clean_X_train_tree = pd.read_csv('../Processed_Data/tennis_all_feature_clean_X_train_tree.csv')\n",
    "tennis_all_feature_clean_X_test_tree = pd.read_csv('../Processed_Data/tennis_all_feature_clean_X_test_tree.csv')\n",
    "tennis_all_feature_clean_drop_oppo_X_train_tree = pd.read_csv('../Processed_Data/tennis_all_feature_clean_drop_oppo_X_train_tree.csv')\n",
    "tennis_all_feature_clean_drop_oppo_X_test_tree = pd.read_csv('../Processed_Data/tennis_all_feature_clean_drop_oppo_X_test_tree.csv')\n",
    "\n",
    "tennis_all_feature_clean_X_train_PCA = pd.read_csv('../Processed_Data/tennis_all_feature_clean_X_train_PCA.csv')\n",
    "tennis_all_feature_clean_X_test_PCA = pd.read_csv('../Processed_Data/tennis_all_feature_clean_X_test_PCA.csv')\n",
    "tennis_all_feature_clean_drop_oppo_X_train_PCA = pd.read_csv('../Processed_Data/tennis_all_feature_clean_drop_oppo_X_train_PCA.csv')\n",
    "tennis_all_feature_clean_drop_oppo_X_test_PCA = pd.read_csv('../Processed_Data/tennis_all_feature_clean_drop_oppo_X_test_PCA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8962, 500)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tennis_all_feature_clean_X_train_p_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8962, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tennis_all_feature_clean_y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fitting the model, we need to see the base score we have to beat, the base score is basically calculated by the random guessing of the majority types in outcome variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.53253\n",
       "0    0.46747\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tennis_all_feature_clean_y_train['1'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the base score we are trying to beat is 0.533, since if we predict every match that the player_1 is winning the current match, we will get 0.533, we will start to fit different models to find out the best in terms of fitting time, predicting accuracy...etc., we will do the grid search on hyperparameters of the algorithms and find out the best one that gives the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "We will first try the simplest algorithm naive bayes, the basic assumptions of the naive bayes is the variables are independent to each other, this is more like an ideal assumption that almost never happens in the real world, but we will still see how it works since the algorithm is simple and fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data dictionary\n",
    "data_all_train = {'all_feature': tennis_all_feature_clean_X_train, \n",
    "                  'all_feature_drop_oppo': tennis_all_feature_clean_drop_oppo_X_train,\n",
    "                  'all_feature_p_value': tennis_all_feature_clean_X_train_p_value, \n",
    "                  'all_feature_drop_oppo_p_value': tennis_all_feature_clean_drop_oppo_X_train_p_value,\n",
    "                  'all_feature_tree': tennis_all_feature_clean_X_train_tree, \n",
    "                  'all_feature_drop_oppo_tree': tennis_all_feature_clean_drop_oppo_X_train_tree,\n",
    "                  'all_feature_PCA': tennis_all_feature_clean_X_train_PCA, \n",
    "                  'all_feature_drop_oppo_PCA': tennis_all_feature_clean_drop_oppo_X_train_PCA}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dictionary to collect all the score and all the best parameters\n",
    "all_score = {}\n",
    "all_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_feature\n",
      "training set size: (8962, 2280)\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7007364427583129\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.667\n",
      "Average Time to Score (s): 0.121\n",
      "\n",
      "\n",
      "all_feature_drop_oppo\n",
      "training set size: (8962, 1540)\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.6967194822584245\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.423\n",
      "Average Time to Score (s): 0.083\n",
      "\n",
      "\n",
      "all_feature_p_value\n",
      "training set size: (8962, 500)\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7194822584244588\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.125\n",
      "Average Time to Score (s): 0.029\n",
      "\n",
      "\n",
      "all_feature_drop_oppo_p_value\n",
      "training set size: (8962, 500)\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7045302387859853\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.124\n",
      "Average Time to Score (s): 0.027\n",
      "\n",
      "\n",
      "all_feature_tree\n",
      "training set size: (8962, 500)\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7085471992858737\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.123\n",
      "Average Time to Score (s): 0.027\n",
      "\n",
      "\n",
      "all_feature_drop_oppo_tree\n",
      "training set size: (8962, 500)\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.6975005579111805\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.124\n",
      "Average Time to Score (s): 0.028\n",
      "\n",
      "\n",
      "all_feature_PCA\n",
      "training set size: (8962, 547)\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.8116491854496765\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.151\n",
      "Average Time to Score (s): 0.037\n",
      "\n",
      "\n",
      "all_feature_drop_oppo_PCA\n",
      "training set size: (8962, 536)\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.8130997545190806\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.149\n",
      "Average Time to Score (s): 0.036\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive = GaussianNB()\n",
    "\n",
    "# create an empty list to store the scores of naive bayes algorithms\n",
    "all_score['Naive_Bayes'] = []\n",
    "all_params['Naive_Bayes'] = []\n",
    "# specify the hyperparameters we are going to do gridsearch on\n",
    "naive_params = {'var_smoothing': [1e-11, 1e-10, 1e-9, 1e-8, 1e-7]}\n",
    "for name, data in data_all_train.items():\n",
    "    print(name)\n",
    "    print(f'training set size: {data.shape}')\n",
    "    print('-'*90)\n",
    "    best, score = get_best_model_accuracy(naive, naive_params, data, tennis_all_feature_clean_y_train, score='accuracy')\n",
    "    all_score['Naive_Bayes'].append(score)\n",
    "    all_params['Naive_Bayes'].append(best)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suprisingly, the data prepared using PCA outbeat the other in this case, the one with all the features did not show any advantage. Plus the modeling fitting time of PCA-processed data is a lot faster due to less features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-nearest neighbor\n",
    "Next we will try another simple algorithm called KNN, it basically gather the neighbors that are closest to the one we are predicting and each neighbor got a vote, the majority of the vote result will be the predictive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# create an empty list to store the scores of knn algorithms\n",
    "all_score['KNN'] = []\n",
    "all_params['KNN'] = []\n",
    "knn_params = {'n_neighbors': [1,3,5,7,9,11]}\n",
    "\n",
    "for name, data in data_all_train.items():\n",
    "    print(name)\n",
    "    print(f'training set size: {data.shape}')\n",
    "    print('-'*90)\n",
    "    best, score = get_best_model_accuracy(knn, knn_params, data, tennis_all_feature_clean_y_train, score='accuracy')\n",
    "    all_score['KNN'].append(score)\n",
    "    all_params['KNN'].append(best)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "Now we will try the logistic regression, this is a more complicated algorithms than the previous two, it basically utilize the sigmoid function to calculate the probability of an example and use it to predict the outcome value, the default probability is set to be 0.5, when the hypothesis is greater or equal to 0.5, it will predict 1 and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_feature\n",
      "training set size: (8962, 2280)\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.8975675072528454\n",
      "Best Parameters: {'C': 0.01, 'penalty': 'l1'}\n",
      "Average Time to Fit (s): 27.881\n",
      "Average Time to Score (s): 0.024\n",
      "\n",
      "\n",
      "all_feature_drop_oppo\n",
      "training set size: (8962, 1540)\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.8981254184333854\n",
      "Best Parameters: {'C': 0.01, 'penalty': 'l1'}\n",
      "Average Time to Fit (s): 24.806\n",
      "Average Time to Score (s): 0.017\n",
      "\n",
      "\n",
      "all_feature_p_value\n",
      "training set size: (8962, 500)\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.8629770140593618\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l1'}\n",
      "Average Time to Fit (s): 8.388\n",
      "Average Time to Score (s): 0.006\n",
      "\n",
      "\n",
      "all_feature_drop_oppo_p_value\n",
      "training set size: (8962, 500)\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.8585137246150413\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l1'}\n",
      "Average Time to Fit (s): 4.962\n",
      "Average Time to Score (s): 0.005\n",
      "\n",
      "\n",
      "all_feature_tree\n",
      "training set size: (8962, 500)\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.8972327605445213\n",
      "Best Parameters: {'C': 0.01, 'penalty': 'l1'}\n",
      "Average Time to Fit (s): 4.972\n",
      "Average Time to Score (s): 0.005\n",
      "\n",
      "\n",
      "all_feature_drop_oppo_tree\n",
      "training set size: (8962, 500)\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "\n",
    "# create an empty list to store the scores of logistic regress algorithms\n",
    "all_score['Logistic_regression'] = []\n",
    "all_params['Logistic_regression'] = []\n",
    "lgr_params = {'penalty': ['l1', 'l2'],\n",
    "              'C': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "for name, data in data_all_train.items():\n",
    "    print(name)\n",
    "    print(f'training set size: {data.shape}')\n",
    "    print('-'*90)\n",
    "    best, score = get_best_model_accuracy(lgr, lgr_params, data, tennis_all_feature_clean_y_train, score='accuracy')\n",
    "    all_score['Logistic_regression'].append(score)\n",
    "    all_params['Logistic_regression'].append(best)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
