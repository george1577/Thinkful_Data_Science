{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Onset Detection -- Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "1. Try different algorithms and build the prediction model\n",
    "    * Naive Bayes\n",
    "    * K-Nearest Neighbors\n",
    "    * Logistic Regression\n",
    "    * Random Forest\n",
    "    * Support Vector Machine\n",
    "    * Gradient Boosting\n",
    "    * Neural Network\n",
    "2. Compare the performance of different imputation and normalization methods\n",
    "    * impute with mean\n",
    "    * impute with median\n",
    "    * z-score normalization\n",
    "    * min-max scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# import model package\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# import customized package\n",
    "from MLuseful import get_best_model_accuracy\n",
    "from MLuseful import roc_curve_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "We will load the training and testing set from the feature engineering step and we will be ready to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('../Data/diabetes_outliers_clean.csv')\n",
    "\n",
    "diabetes_mean_X_train_z = pd.read_csv('../Data/diabetes_mean_X_train_z.csv')\n",
    "diabetes_mean_X_test_z = pd.read_csv('../Data/diabetes_mean_X_test_z.csv')\n",
    "diabetes_median_X_train_z = pd.read_csv('../Data/diabetes_median_X_train_z.csv')\n",
    "diabetes_median_X_test_z = pd.read_csv('../Data/diabetes_median_X_test_z.csv')\n",
    "\n",
    "diabetes_mean_X_train_min_max = pd.read_csv('../Data/diabetes_mean_X_train_min_max.csv')\n",
    "diabetes_mean_X_test_min_max = pd.read_csv('../Data/diabetes_mean_X_test_min_max.csv')\n",
    "diabetes_median_X_train_min_max = pd.read_csv('../Data/diabetes_median_X_train_min_max.csv')\n",
    "diabetes_median_X_test_min_max = pd.read_csv('../Data/diabetes_median_X_test_min_max.csv')\n",
    "\n",
    "diabetes_y_train = pd.read_csv('../Data/diabetes_y_train.csv', header=None)\n",
    "diabetes_y_test = pd.read_csv('../Data/diabetes_y_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fitting the model, we need to see the base score we have to beat, the base score is basically calculated by the random guessing of the majority types in outcome variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.651042\n",
       "1    0.348958\n",
       "Name: Outcome, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes['Outcome'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, we can see the baseline score we need to beat is 0.651, since if we predict all the patients have no diabetes, we will get a score of 0.651. We will start to fit different models to find out the best in terms of fitting time, predicting accuracy...etc., we will do the grid search on hyperparameters of the algorithms and find out the best one that gives the highest accuracy, since accuracy might not be enough for the error metrics, we will discuss more about it later, at this time we will use the accuracy score determine the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "We will first try the simplest algorithm naive bayes, the basic assumptions of the naive bayes is the variables are independent to each other, this is more like an ideal assumption that almost never happens in the real world, but we will still see how it works since the algorithm is simple and fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = [(diabetes_mean_X_train_z, 'mean-z-score'), (diabetes_median_X_train_z, 'median-z-score'), \n",
    "        (diabetes_mean_X_train_min_max, 'mean-min-max'), (diabetes_median_X_train_min_max, 'median-min-max')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best Accuracy: 0.7486033519553073\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best Accuracy: 0.74487895716946\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "mean-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best Accuracy: 0.7486033519553073\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.002\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best Accuracy: 0.74487895716946\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive = GaussianNB()\n",
    "\n",
    "# specify the hyperparameters we are going to do gridsearch on\n",
    "naive_params = {'var_smoothing': [1e-11, 1e-10, 1e-9, 1e-8, 1e-7]}\n",
    "for data in data_all:\n",
    "    print(data[1])\n",
    "    print('-'*90)\n",
    "    best = get_best_model_accuracy(naive, naive_params, data[0], diabetes_y_train)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best Accuracy: 0.770949720670391\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l1'}\n",
      "Average Time to Fit (s): 0.004\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best Accuracy: 0.770949720670391\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l1'}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "mean-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best Accuracy: 0.7728119180633147\n",
      "Best Parameters: {'C': 1, 'penalty': 'l2'}\n",
      "Average Time to Fit (s): 0.006\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best Accuracy: 0.7728119180633147\n",
      "Best Parameters: {'C': 1, 'penalty': 'l2'}\n",
      "Average Time to Fit (s): 0.006\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr_params = {'penalty': ['l1', 'l2'],\n",
    "              'C': [0.01, 0.1, 1, 10]}\n",
    "for data in data_all:\n",
    "    print(data[1])\n",
    "    print('-'*90)\n",
    "    best = get_best_model_accuracy(lgr, lgr_params, data[0], diabetes_y_train)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
