{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Onset Detection -- Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "1. Try different algorithms and build the prediction model\n",
    "    * Naive Bayes\n",
    "    * K-Nearest Neighbors\n",
    "    * Logistic Regression\n",
    "    * Decision Tree\n",
    "    * Random Forest\n",
    "    * Support Vector Machine\n",
    "    * Gradient Boosting\n",
    "    * Neural Network\n",
    "2. Compare the performance of different imputation and normalization methods\n",
    "    * impute with mean\n",
    "    * impute with median\n",
    "    * z-score normalization\n",
    "    * min-max scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# import model package\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# import customized package\n",
    "from MLuseful import get_best_model_accuracy\n",
    "from MLuseful import roc_curve_plot\n",
    "from MLuseful import print_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "We will load the training and testing set from the feature engineering step and we will be ready to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('../Data/diabetes_outliers_clean.csv')\n",
    "\n",
    "# z-score normalization\n",
    "diabetes_mean_X_train_z = pd.read_csv('../Data/diabetes_mean_X_train_z.csv')\n",
    "diabetes_mean_X_test_z = pd.read_csv('../Data/diabetes_mean_X_test_z.csv')\n",
    "diabetes_median_X_train_z = pd.read_csv('../Data/diabetes_median_X_train_z.csv')\n",
    "diabetes_median_X_test_z = pd.read_csv('../Data/diabetes_median_X_test_z.csv')\n",
    "diabetes_mean_X_train_z_PCA = pd.read_csv('../Data/diabetes_mean_X_train_z_PCA.csv')\n",
    "diabetes_median_X_train_z_PCA = pd.read_csv('../Data/diabetes_median_X_train_z_PCA.csv')\n",
    "diabetes_mean_X_test_z_PCA = pd.read_csv('../Data/diabetes_mean_X_test_z_PCA.csv')\n",
    "diabetes_median_X_test_z_PCA = pd.read_csv('../Data/diabetes_median_X_test_z_PCA.csv')\n",
    "\n",
    "# min-max scaling\n",
    "diabetes_mean_X_train_min_max = pd.read_csv('../Data/diabetes_mean_X_train_min_max.csv')\n",
    "diabetes_mean_X_test_min_max = pd.read_csv('../Data/diabetes_mean_X_test_min_max.csv')\n",
    "diabetes_median_X_train_min_max = pd.read_csv('../Data/diabetes_median_X_train_min_max.csv')\n",
    "diabetes_median_X_test_min_max = pd.read_csv('../Data/diabetes_median_X_test_min_max.csv')\n",
    "diabetes_mean_X_train_min_max_PCA = pd.read_csv('../Data/diabetes_mean_X_train_min_max_PCA.csv')\n",
    "diabetes_median_X_train_min_max_PCA = pd.read_csv('../Data/diabetes_median_X_train_min_max_PCA.csv')\n",
    "diabetes_mean_X_test_min_max_PCA = pd.read_csv('../Data/diabetes_mean_X_test_min_max_PCA.csv')\n",
    "diabetes_median_X_test_min_max_PCA = pd.read_csv('../Data/diabetes_median_X_test_min_max_PCA.csv')\n",
    "\n",
    "diabetes_y_train = pd.read_csv('../Data/diabetes_y_train.csv', header=None)\n",
    "diabetes_y_test = pd.read_csv('../Data/diabetes_y_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fitting the model, we need to see the base score we have to beat, the base score is basically calculated by the random guessing of the majority types in outcome variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.651042\n",
       "1    0.348958\n",
       "Name: Outcome, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes['Outcome'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, we can see the baseline score we need to beat is 0.651, since if we predict all the patients have no diabetes, we will get a score of 0.651. We will start to fit different models to find out the best in terms of fitting time, predicting accuracy...etc., we will do the grid search on hyperparameters of the algorithms and find out the best one that gives the highest accuracy, since accuracy might not be enough for the error metrics, we will discuss more about it later, at this time we will use the accuracy score determine the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "We will first try the simplest algorithm naive bayes, the basic assumptions of the naive bayes is the variables are independent to each other, this is more like an ideal assumption that almost never happens in the real world, but we will still see how it works since the algorithm is simple and fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will include all the data we gathered and processed from data cleaning and feature engineering step, there is no need to split the data into training and testing set again since we already did it in previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data collection\n",
    "data_all = [(diabetes_mean_X_train_z, 'mean-z-score'), (diabetes_median_X_train_z, 'median-z-score'), \n",
    "(diabetes_mean_X_train_min_max, 'mean-min-max'), (diabetes_median_X_train_min_max, 'median-min-max'),\n",
    "(diabetes_mean_X_train_z_PCA, 'mean-z-score-PCA'), (diabetes_median_X_train_z_PCA, 'median-z-score-PCA'),\n",
    "(diabetes_mean_X_train_min_max_PCA, 'mean-min-max-PCA'), (diabetes_median_X_train_min_max_PCA, 'median-min-max-PCA')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dictionary to collect all the score and all the best parameters\n",
    "all_score = {}\n",
    "all_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7486033519553073\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.74487895716946\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.002\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "mean-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7486033519553073\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.74487895716946\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "mean-z-score-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7001862197392924\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-z-score-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.6945996275605214\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.002\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "mean-min-max-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7001862197392924\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.002\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-min-max-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7039106145251397\n",
      "Best Parameters: {'var_smoothing': 1e-11}\n",
      "Average Time to Fit (s): 0.002\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive = GaussianNB()\n",
    "\n",
    "# create an empty list to store the scores of naive bayes algorithms\n",
    "all_score['Naive_Bayes'] = []\n",
    "all_params['Naive_Bayes'] = []\n",
    "# specify the hyperparameters we are going to do gridsearch on\n",
    "naive_params = {'var_smoothing': [1e-11, 1e-10, 1e-9, 1e-8, 1e-7]}\n",
    "for data in data_all:\n",
    "    print(data[1])\n",
    "    print('-'*90)\n",
    "    best, score = get_best_model_accuracy(naive, naive_params, data[0], diabetes_y_train, score='accuracy')\n",
    "    all_score['Naive_Bayes'].append(score)\n",
    "    all_params['Naive_Bayes'].append(best_nv)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like for naive bias, the z-score and min-max method does not have much difference, for the PCA data, it looks like it does not help with the prediction, the accuracy score is lower than without the PCA, we have only tuned one hyperparameter here and it looks like `var_smoothing` = 1e-11 is the best for all models, the best accuracy score we got is 0.7486"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-nearest neighbor\n",
    "Next we will try another simple algorithm called KNN, it basically gather the neighbors that are closest to the one we are predicting and each neighbor got a vote, the majority of the vote result will be the predictive value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.770949720670391\n",
      "Best Parameters: {'n_neighbors': 9}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.003\n",
      "\n",
      "\n",
      "median-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.776536312849162\n",
      "Best Parameters: {'n_neighbors': 11}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.003\n",
      "\n",
      "\n",
      "mean-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.776536312849162\n",
      "Best Parameters: {'n_neighbors': 9}\n",
      "Average Time to Fit (s): 0.002\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "median-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7783985102420856\n",
      "Best Parameters: {'n_neighbors': 9}\n",
      "Average Time to Fit (s): 0.002\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "mean-z-score-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7281191806331471\n",
      "Best Parameters: {'n_neighbors': 7}\n",
      "Average Time to Fit (s): 0.002\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "median-z-score-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7206703910614525\n",
      "Best Parameters: {'n_neighbors': 7}\n",
      "Average Time to Fit (s): 0.002\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "mean-min-max-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7318435754189944\n",
      "Best Parameters: {'n_neighbors': 5}\n",
      "Average Time to Fit (s): 0.002\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "median-min-max-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7243947858472998\n",
      "Best Parameters: {'n_neighbors': 7}\n",
      "Average Time to Fit (s): 0.002\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# create an empty list to store the scores of knn algorithms\n",
    "all_score['KNN'] = []\n",
    "all_params['KNN'] = []\n",
    "knn_params = {'n_neighbors': [1,3,5,7,9,11]}\n",
    "\n",
    "for data in data_all:\n",
    "    print(data[1])\n",
    "    print('-'*90)\n",
    "    best, score = get_best_model_accuracy(knn, knn_params, data[0], diabetes_y_train, score='accuracy')\n",
    "    all_score['KNN'].append(score)\n",
    "    all_params['KNN'].append(best)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as naive bayes, PCA data perform worse than the feature engineered data group, note that each data has its own best hyperparameter, the highest accuracy score we got using knn algorithm is 0.7784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "Now we will try the logistic regression, this is a more complicated algorithms than our previous two, it basically utilize the sigmoid function to calculate the probability of an example and use it to predict the outcome value, the default probability is set to be 0.5, when the hypothesis is greater or equal to 0.5, it will predict 1 and 0 otherwise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.770949720670391\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l1'}\n",
      "Average Time to Fit (s): 0.004\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.770949720670391\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l1'}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "mean-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7728119180633147\n",
      "Best Parameters: {'C': 1, 'penalty': 'l2'}\n",
      "Average Time to Fit (s): 0.006\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7728119180633147\n",
      "Best Parameters: {'C': 1, 'penalty': 'l2'}\n",
      "Average Time to Fit (s): 0.006\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "mean-z-score-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7206703910614525\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l1'}\n",
      "Average Time to Fit (s): 0.002\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-z-score-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7262569832402235\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l1'}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "mean-min-max-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7355679702048417\n",
      "Best Parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-min-max-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7374301675977654\n",
      "Best Parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "\n",
    "# create an empty list to store the scores of logistic regress algorithms\n",
    "all_score['Logistic_regression'] = []\n",
    "all_params['Logistic_regression'] = []\n",
    "lgr_params = {'penalty': ['l1', 'l2'],\n",
    "              'C': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "for data in data_all:\n",
    "    print(data[1])\n",
    "    print('-'*90)\n",
    "    best, score = get_best_model_accuracy(lgr, lgr_params, data[0], diabetes_y_train, score='accuracy')\n",
    "    all_score['Logistic_regression'].append(score)\n",
    "    all_params['Logistic_regression'].append(best)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same trend of PCA data perform worse than feature engineered data still hold in logistic regression, the best score we got here is 0.7728, one thing to note that the average time to fit the model seems slightly longer, this suggest logistic regression algorithm is more complicated than naive bayes and knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree\n",
    "We will now test our tree model, this algorithm is different from previous models we fit, it basically uses a certain criteria to separate the data into two groups in each branch, the criteria is based on the maximum information gain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7374301675977654\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 5}\n",
      "Average Time to Fit (s): 0.004\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7467411545623837\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 5}\n",
      "Average Time to Fit (s): 0.005\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "mean-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7411545623836127\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 5}\n",
      "Average Time to Fit (s): 0.004\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7430167597765364\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 5}\n",
      "Average Time to Fit (s): 0.004\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "mean-z-score-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7057728119180633\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 3}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-z-score-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7281191806331471\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 5}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "mean-min-max-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7225325884543762\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 9}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-min-max-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7281191806331471\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 3}\n",
      "Average Time to Fit (s): 0.003\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# create an empty list to store the scores of tree algorithms\n",
    "all_score['Decision_tree'] = []\n",
    "all_params['Decision_tree'] = []\n",
    "\n",
    "dt_params = {'criterion': ['gini', 'entropy'],\n",
    "             'max_depth': [1,3,5,7,9,11],}\n",
    "\n",
    "for data in data_all:\n",
    "    print(data[1])\n",
    "    print('-'*90)\n",
    "    best, score = get_best_model_accuracy(dt, dt_params, data[0], diabetes_y_train, score='accuracy')\n",
    "    all_score['Decision_tree'].append(score)\n",
    "    all_params['Decision_tree'].append(best)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree model has the highest score of 0.7467, it is comparable to the naive bayes model, since this is a single tree model, next we will take multiple trees altogether to improve our performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest\n",
    "Random forest algorithm is based on the decision tree, it is an ensemble model that takes the random patch of the data each time and build a decision tree based on that, it then create multiple decision trees and take the maximum voting as the final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7690875232774674\n",
      "Best Parameters: {'max_depth': 5, 'n_estimators': 50}\n",
      "Average Time to Fit (s): 0.177\n",
      "Average Time to Score (s): 0.018\n",
      "\n",
      "\n",
      "median-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7746741154562383\n",
      "Best Parameters: {'max_depth': 7, 'n_estimators': 500}\n",
      "Average Time to Fit (s): 0.183\n",
      "Average Time to Score (s): 0.018\n",
      "\n",
      "\n",
      "mean-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.776536312849162\n",
      "Best Parameters: {'max_depth': 9, 'n_estimators': 50}\n",
      "Average Time to Fit (s): 0.18\n",
      "Average Time to Score (s): 0.018\n",
      "\n",
      "\n",
      "median-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7783985102420856\n",
      "Best Parameters: {'max_depth': 9, 'n_estimators': 100}\n",
      "Average Time to Fit (s): 0.209\n",
      "Average Time to Score (s): 0.022\n",
      "\n",
      "\n",
      "mean-z-score-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7430167597765364\n",
      "Best Parameters: {'max_depth': 3, 'n_estimators': 500}\n",
      "Average Time to Fit (s): 0.169\n",
      "Average Time to Score (s): 0.018\n",
      "\n",
      "\n",
      "median-z-score-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7467411545623837\n",
      "Best Parameters: {'max_depth': 3, 'n_estimators': 100}\n",
      "Average Time to Fit (s): 0.167\n",
      "Average Time to Score (s): 0.018\n",
      "\n",
      "\n",
      "mean-min-max-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7467411545623837\n",
      "Best Parameters: {'max_depth': 7, 'n_estimators': 10}\n",
      "Average Time to Fit (s): 0.186\n",
      "Average Time to Score (s): 0.02\n",
      "\n",
      "\n",
      "median-min-max-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7616387337057728\n",
      "Best Parameters: {'max_depth': 5, 'n_estimators': 10}\n",
      "Average Time to Fit (s): 0.181\n",
      "Average Time to Score (s): 0.019\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "# create an empty list to store the scores of tree algorithms\n",
    "all_score['Random_forest'] = []\n",
    "all_params['Random_forest'] = []\n",
    "\n",
    "rf_params = {'n_estimators': [10, 50, 100, 500],\n",
    "             'max_depth': [1,3,5,7,9]}\n",
    "\n",
    "for data in data_all:\n",
    "    print(data[1])\n",
    "    print('-'*90)\n",
    "    best, score = get_best_model_accuracy(rf, rf_params, data[0], diabetes_y_train, score='accuracy')\n",
    "    all_score['Random_forest'].append(score)\n",
    "    all_params['Random_forest'].append(best)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the average score of random forest is better than the decision tree, the best score we can get here is 0.7765, however, we can also see that the average time to fit the model is a lot longer than the decision tree, this is clearly a trade-off between accuracy score and model fitting time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support vector machine\n",
    "We will next try the support vector machine, this algorithms has a cost function that is modified from logistic regression, the modified version of cost function creates an ideal hyperplance in an n-dimensional space that separates the class with the maximum margin, we will first try the linear support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7653631284916201\n",
      "Best Parameters: {'C': 0.01, 'penalty': 'l2'}\n",
      "Average Time to Fit (s): 0.01\n",
      "Average Time to Score (s): 0.0\n",
      "\n",
      "\n",
      "median-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7672253258845437\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l2'}\n",
      "Average Time to Fit (s): 0.009\n",
      "Average Time to Score (s): 0.0\n",
      "\n",
      "\n",
      "mean-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.776536312849162\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l2'}\n",
      "Average Time to Fit (s): 0.007\n",
      "Average Time to Score (s): 0.0\n",
      "\n",
      "\n",
      "median-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7728119180633147\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l2'}\n",
      "Average Time to Fit (s): 0.007\n",
      "Average Time to Score (s): 0.0\n",
      "\n",
      "\n",
      "mean-z-score-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7262569832402235\n",
      "Best Parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Average Time to Fit (s): 0.007\n",
      "Average Time to Score (s): 0.0\n",
      "\n",
      "\n",
      "median-z-score-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7188081936685289\n",
      "Best Parameters: {'C': 0.01, 'penalty': 'l2'}\n",
      "Average Time to Fit (s): 0.007\n",
      "Average Time to Score (s): 0.0\n",
      "\n",
      "\n",
      "mean-min-max-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7374301675977654\n",
      "Best Parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Average Time to Fit (s): 0.005\n",
      "Average Time to Score (s): 0.0\n",
      "\n",
      "\n",
      "median-min-max-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7392923649906891\n",
      "Best Parameters: {'C': 100, 'penalty': 'l2'}\n",
      "Average Time to Fit (s): 0.005\n",
      "Average Time to Score (s): 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# linear support vector machine\n",
    "lsvc = LinearSVC()\n",
    "\n",
    "# create an empty list to store the scores of linear support vector machine algorithms\n",
    "all_score['LSVM'] = []\n",
    "all_params['LSVM'] = []\n",
    "lsvc_params = {'C': [0.01, 0.1, 1, 10, 100],\n",
    "               'penalty': ['l1', 'l2']}\n",
    "for data in data_all:\n",
    "    print(data[1])\n",
    "    print('-'*90)\n",
    "    best, score = get_best_model_accuracy(lsvc, lsvc_params, data[0], diabetes_y_train, score='accuracy')\n",
    "    all_score['LSVM'].append(score)\n",
    "    all_params['LSVM'].append(best)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best score we got from linear support vector machine is 0.7765 and we can see that the average fitting time is quite fast, we will next try the non-linear kernel model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7635009310986964\n",
      "Best Parameters: {'C': 1, 'kernel': 'rbf'}\n",
      "Average Time to Fit (s): 0.016\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "median-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7616387337057728\n",
      "Best Parameters: {'C': 1, 'kernel': 'rbf'}\n",
      "Average Time to Fit (s): 0.015\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "mean-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7746741154562383\n",
      "Best Parameters: {'C': 100, 'kernel': 'poly'}\n",
      "Average Time to Fit (s): 0.006\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "median-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7728119180633147\n",
      "Best Parameters: {'C': 100, 'kernel': 'poly'}\n",
      "Average Time to Fit (s): 0.006\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "mean-z-score-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7299813780260708\n",
      "Best Parameters: {'C': 10, 'kernel': 'rbf'}\n",
      "Average Time to Fit (s): 0.225\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "median-z-score-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7188081936685289\n",
      "Best Parameters: {'C': 1, 'kernel': 'rbf'}\n",
      "Average Time to Fit (s): 0.234\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "mean-min-max-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7374301675977654\n",
      "Best Parameters: {'C': 1, 'kernel': 'rbf'}\n",
      "Average Time to Fit (s): 0.006\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-min-max-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7392923649906891\n",
      "Best Parameters: {'C': 1, 'kernel': 'rbf'}\n",
      "Average Time to Fit (s): 0.006\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svc with non-linear kernel\n",
    "svc = SVC()\n",
    "\n",
    "# create an empty list to store the scores of non-linear support vector machine algorithms\n",
    "all_score['SVM'] = []\n",
    "all_params['SVM'] = []\n",
    "svc_params = {'C': [0.01, 0.1, 1, 10, 100],\n",
    "              'kernel': ['rbf', 'poly']}\n",
    "for data in data_all:\n",
    "    print(data[1])\n",
    "    print('-'*90)\n",
    "    best, score = get_best_model_accuracy(svc, svc_params, data[0], diabetes_y_train, score='accuracy')\n",
    "    all_score['SVM'].append(score)\n",
    "    all_params['SVM'].append(best)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-linear kernel support vector machine in this case actually has a lower score than the linear svm, the best score we got is 0.7747"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient boosting\n",
    "Next we will try another ensemble model called gradient boosting, this algorithm basically use the weak learner model, at first the model will perform badly, however we will use another weak leaner to fit the unexplained residue from the previous weak learner, repeat it in series until we get the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7616387337057728\n",
      "Best Parameters: {'learning_rate': 0.05, 'n_estimators': 100}\n",
      "Average Time to Fit (s): 0.2\n",
      "Average Time to Score (s): 0.001\n",
      "\n",
      "\n",
      "median-z-score\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7635009310986964\n",
      "Best Parameters: {'learning_rate': 0.01, 'n_estimators': 500}\n",
      "Average Time to Fit (s): 0.203\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "mean-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7653631284916201\n",
      "Best Parameters: {'learning_rate': 0.05, 'n_estimators': 100}\n",
      "Average Time to Fit (s): 0.209\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "median-min-max\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7635009310986964\n",
      "Best Parameters: {'learning_rate': 0.05, 'n_estimators': 50}\n",
      "Average Time to Fit (s): 0.209\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "mean-z-score-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7430167597765364\n",
      "Best Parameters: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Average Time to Fit (s): 0.175\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "median-z-score-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7430167597765364\n",
      "Best Parameters: {'learning_rate': 0.05, 'n_estimators': 50}\n",
      "Average Time to Fit (s): 0.174\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "mean-min-max-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.7374301675977654\n",
      "Best Parameters: {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "Average Time to Fit (s): 0.187\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n",
      "median-min-max-PCA\n",
      "------------------------------------------------------------------------------------------\n",
      "Best accuracy : 0.74487895716946\n",
      "Best Parameters: {'learning_rate': 0.05, 'n_estimators': 50}\n",
      "Average Time to Fit (s): 0.183\n",
      "Average Time to Score (s): 0.002\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingClassifier()\n",
    "\n",
    "# create an empty list to store the scores of gradient boosting algorithms\n",
    "all_score['Gradient_boosting'] = []\n",
    "all_params['Gradient_boosting'] = []\n",
    "gbr_params = {'learning_rate': [0.01, 0.05, 0.1, 0.5, 1],\n",
    "              'n_estimators': [50, 100, 500]}\n",
    "\n",
    "for data in data_all:\n",
    "    print(data[1])\n",
    "    print('-'*90)\n",
    "    best, score = get_best_model_accuracy(gbr, gbr_params, data[0], diabetes_y_train, score='accuracy')\n",
    "    all_score['Gradient_boosting'].append(score)\n",
    "    all_params['Gradient_boosting'].append(best)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that gradient boosting takes a while to fit the model, mostly due to the reason that it fits the weak learner in series, the best score we got is 0.7653"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have gather all the scores and parameters from the model we fit, we will show the summary table as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive_Bayes</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic_regression</th>\n",
       "      <th>Decision_tree</th>\n",
       "      <th>Random_forest</th>\n",
       "      <th>LSVM</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Gradient_boosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean-z-score</th>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>0.769088</td>\n",
       "      <td>0.765363</td>\n",
       "      <td>0.763501</td>\n",
       "      <td>0.761639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median-z-score</th>\n",
       "      <td>0.744879</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.746741</td>\n",
       "      <td>0.774674</td>\n",
       "      <td>0.767225</td>\n",
       "      <td>0.761639</td>\n",
       "      <td>0.763501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean-min-max</th>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.772812</td>\n",
       "      <td>0.741155</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.774674</td>\n",
       "      <td>0.765363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median-min-max</th>\n",
       "      <td>0.744879</td>\n",
       "      <td>0.778399</td>\n",
       "      <td>0.772812</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.778399</td>\n",
       "      <td>0.772812</td>\n",
       "      <td>0.772812</td>\n",
       "      <td>0.763501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean-z-score-PCA</th>\n",
       "      <td>0.700186</td>\n",
       "      <td>0.728119</td>\n",
       "      <td>0.720670</td>\n",
       "      <td>0.705773</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.726257</td>\n",
       "      <td>0.729981</td>\n",
       "      <td>0.743017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median-z-score-PCA</th>\n",
       "      <td>0.694600</td>\n",
       "      <td>0.720670</td>\n",
       "      <td>0.726257</td>\n",
       "      <td>0.728119</td>\n",
       "      <td>0.746741</td>\n",
       "      <td>0.718808</td>\n",
       "      <td>0.718808</td>\n",
       "      <td>0.743017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean-min-max-PCA</th>\n",
       "      <td>0.700186</td>\n",
       "      <td>0.731844</td>\n",
       "      <td>0.735568</td>\n",
       "      <td>0.722533</td>\n",
       "      <td>0.746741</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>0.737430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median-min-max-PCA</th>\n",
       "      <td>0.703911</td>\n",
       "      <td>0.724395</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>0.728119</td>\n",
       "      <td>0.761639</td>\n",
       "      <td>0.739292</td>\n",
       "      <td>0.739292</td>\n",
       "      <td>0.744879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Naive_Bayes       KNN  Logistic_regression  Decision_tree  \\\n",
       "mean-z-score           0.748603  0.770950             0.770950       0.737430   \n",
       "median-z-score         0.744879  0.776536             0.770950       0.746741   \n",
       "mean-min-max           0.748603  0.776536             0.772812       0.741155   \n",
       "median-min-max         0.744879  0.778399             0.772812       0.743017   \n",
       "mean-z-score-PCA       0.700186  0.728119             0.720670       0.705773   \n",
       "median-z-score-PCA     0.694600  0.720670             0.726257       0.728119   \n",
       "mean-min-max-PCA       0.700186  0.731844             0.735568       0.722533   \n",
       "median-min-max-PCA     0.703911  0.724395             0.737430       0.728119   \n",
       "\n",
       "                    Random_forest      LSVM       SVM  Gradient_boosting  \n",
       "mean-z-score             0.769088  0.765363  0.763501           0.761639  \n",
       "median-z-score           0.774674  0.767225  0.761639           0.763501  \n",
       "mean-min-max             0.776536  0.776536  0.774674           0.765363  \n",
       "median-min-max           0.778399  0.772812  0.772812           0.763501  \n",
       "mean-z-score-PCA         0.743017  0.726257  0.729981           0.743017  \n",
       "median-z-score-PCA       0.746741  0.718808  0.718808           0.743017  \n",
       "mean-min-max-PCA         0.746741  0.737430  0.737430           0.737430  \n",
       "median-min-max-PCA       0.761639  0.739292  0.739292           0.744879  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dataframe for the score\n",
    "all_score_df = pd.DataFrame(all_score, index=['mean-z-score', 'median-z-score', 'mean-min-max',\n",
    "                                              'median-min-max', 'mean-z-score-PCA', 'median-z-score-PCA',\n",
    "                                              'mean-min-max-PCA', 'median-min-max-PCA'])\n",
    "all_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive_Bayes</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic_regression</th>\n",
       "      <th>Decision_tree</th>\n",
       "      <th>Random_forest</th>\n",
       "      <th>LSVM</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Gradient_boosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean-z-score</th>\n",
       "      <td>{'var_smoothing': 1e-11}</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5}</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median-z-score</th>\n",
       "      <td>{'var_smoothing': 1e-11}</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5}</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 500}</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 500}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean-min-max</th>\n",
       "      <td>{'var_smoothing': 1e-11}</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5}</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 50}</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 100, 'kernel': 'poly'}</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median-min-max</th>\n",
       "      <td>{'var_smoothing': 1e-11}</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5}</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 100}</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 100, 'kernel': 'poly'}</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean-z-score-PCA</th>\n",
       "      <td>{'var_smoothing': 1e-11}</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3}</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 500}</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median-z-score-PCA</th>\n",
       "      <td>{'var_smoothing': 1e-11}</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5}</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean-min-max-PCA</th>\n",
       "      <td>{'var_smoothing': 1e-11}</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 9}</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 10}</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median-min-max-PCA</th>\n",
       "      <td>{'var_smoothing': 1e-11}</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3}</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 10}</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Naive_Bayes                  KNN  \\\n",
       "mean-z-score        {'var_smoothing': 1e-11}   {'n_neighbors': 9}   \n",
       "median-z-score      {'var_smoothing': 1e-11}  {'n_neighbors': 11}   \n",
       "mean-min-max        {'var_smoothing': 1e-11}   {'n_neighbors': 9}   \n",
       "median-min-max      {'var_smoothing': 1e-11}   {'n_neighbors': 9}   \n",
       "mean-z-score-PCA    {'var_smoothing': 1e-11}   {'n_neighbors': 7}   \n",
       "median-z-score-PCA  {'var_smoothing': 1e-11}   {'n_neighbors': 7}   \n",
       "mean-min-max-PCA    {'var_smoothing': 1e-11}   {'n_neighbors': 5}   \n",
       "median-min-max-PCA  {'var_smoothing': 1e-11}   {'n_neighbors': 7}   \n",
       "\n",
       "                            Logistic_regression  \\\n",
       "mean-z-score        {'C': 0.1, 'penalty': 'l1'}   \n",
       "median-z-score      {'C': 0.1, 'penalty': 'l1'}   \n",
       "mean-min-max          {'C': 1, 'penalty': 'l2'}   \n",
       "median-min-max        {'C': 1, 'penalty': 'l2'}   \n",
       "mean-z-score-PCA    {'C': 0.1, 'penalty': 'l1'}   \n",
       "median-z-score-PCA  {'C': 0.1, 'penalty': 'l1'}   \n",
       "mean-min-max-PCA     {'C': 10, 'penalty': 'l2'}   \n",
       "median-min-max-PCA   {'C': 10, 'penalty': 'l2'}   \n",
       "\n",
       "                                               Decision_tree  \\\n",
       "mean-z-score           {'criterion': 'gini', 'max_depth': 5}   \n",
       "median-z-score         {'criterion': 'gini', 'max_depth': 5}   \n",
       "mean-min-max           {'criterion': 'gini', 'max_depth': 5}   \n",
       "median-min-max         {'criterion': 'gini', 'max_depth': 5}   \n",
       "mean-z-score-PCA       {'criterion': 'gini', 'max_depth': 3}   \n",
       "median-z-score-PCA  {'criterion': 'entropy', 'max_depth': 5}   \n",
       "mean-min-max-PCA       {'criterion': 'gini', 'max_depth': 9}   \n",
       "median-min-max-PCA     {'criterion': 'gini', 'max_depth': 3}   \n",
       "\n",
       "                                            Random_forest  \\\n",
       "mean-z-score         {'max_depth': 5, 'n_estimators': 50}   \n",
       "median-z-score      {'max_depth': 7, 'n_estimators': 500}   \n",
       "mean-min-max         {'max_depth': 9, 'n_estimators': 50}   \n",
       "median-min-max      {'max_depth': 9, 'n_estimators': 100}   \n",
       "mean-z-score-PCA    {'max_depth': 3, 'n_estimators': 500}   \n",
       "median-z-score-PCA  {'max_depth': 3, 'n_estimators': 100}   \n",
       "mean-min-max-PCA     {'max_depth': 7, 'n_estimators': 10}   \n",
       "median-min-max-PCA   {'max_depth': 5, 'n_estimators': 10}   \n",
       "\n",
       "                                            LSVM  \\\n",
       "mean-z-score        {'C': 0.01, 'penalty': 'l2'}   \n",
       "median-z-score       {'C': 0.1, 'penalty': 'l2'}   \n",
       "mean-min-max         {'C': 0.1, 'penalty': 'l2'}   \n",
       "median-min-max       {'C': 0.1, 'penalty': 'l2'}   \n",
       "mean-z-score-PCA      {'C': 10, 'penalty': 'l2'}   \n",
       "median-z-score-PCA  {'C': 0.01, 'penalty': 'l2'}   \n",
       "mean-min-max-PCA      {'C': 10, 'penalty': 'l2'}   \n",
       "median-min-max-PCA   {'C': 100, 'penalty': 'l2'}   \n",
       "\n",
       "                                             SVM  \\\n",
       "mean-z-score           {'C': 1, 'kernel': 'rbf'}   \n",
       "median-z-score         {'C': 1, 'kernel': 'rbf'}   \n",
       "mean-min-max        {'C': 100, 'kernel': 'poly'}   \n",
       "median-min-max      {'C': 100, 'kernel': 'poly'}   \n",
       "mean-z-score-PCA      {'C': 10, 'kernel': 'rbf'}   \n",
       "median-z-score-PCA     {'C': 1, 'kernel': 'rbf'}   \n",
       "mean-min-max-PCA       {'C': 1, 'kernel': 'rbf'}   \n",
       "median-min-max-PCA     {'C': 1, 'kernel': 'rbf'}   \n",
       "\n",
       "                                               Gradient_boosting  \n",
       "mean-z-score        {'learning_rate': 0.05, 'n_estimators': 100}  \n",
       "median-z-score      {'learning_rate': 0.01, 'n_estimators': 500}  \n",
       "mean-min-max        {'learning_rate': 0.05, 'n_estimators': 100}  \n",
       "median-min-max       {'learning_rate': 0.05, 'n_estimators': 50}  \n",
       "mean-z-score-PCA      {'learning_rate': 0.1, 'n_estimators': 50}  \n",
       "median-z-score-PCA   {'learning_rate': 0.05, 'n_estimators': 50}  \n",
       "mean-min-max-PCA    {'learning_rate': 0.01, 'n_estimators': 100}  \n",
       "median-min-max-PCA   {'learning_rate': 0.05, 'n_estimators': 50}  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_params_df = pd.DataFrame(all_params, index=['mean-z-score', 'median-z-score', 'mean-min-max',\n",
    "                                              'median-min-max', 'mean-z-score-PCA', 'median-z-score-PCA',\n",
    "                                              'mean-min-max-PCA', 'median-min-max-PCA'])\n",
    "all_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random_forest          0.762104\n",
       "Gradient_boosting      0.752793\n",
       "Logistic_regression    0.750931\n",
       "KNN                    0.750931\n",
       "LSVM                   0.750466\n",
       "SVM                    0.749767\n",
       "Decision_tree          0.731611\n",
       "Naive_Bayes            0.723231\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the average score of all algorithms\n",
    "all_score_df.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have a winner here if we just take the average score of all the data, the random forest algorithm outperforms the other algorithm and the simple algorithm naive bayes, as expected, has the average lowest score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
